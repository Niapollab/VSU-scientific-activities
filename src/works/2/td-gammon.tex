% !TEX TS-program = lualatex
Разработанный Джеральдом Тесауро в начале 1990-х годов, TD-Gammon произвел революцию в искусственном интеллекте для игры <<Нарды>>, используя архитектуру нейронной сети, обученную с помощью метода <<Обучение с подкреплением>>. Благодаря самостоятельной игре и миллионам имитационных игр TD-Gammon научился оценивать позиции на доске, предсказывать исходы и принимать стратегические решения, устанавливая новый стандарт адаптивного и интеллектуального игрового процесса.

В основе строения нейронных сети данного типа, лежит процесс принятия решений по Маркову, а именно математическое моделирование принятия решений с использованием дискретных временных шагов. На каждом $i$-ом шаге обучения осуществляется выбор некоторого хода $a_i \in A$, где $A$ --- является множеством всех доступных ходов для некоторого состояния $s_i \in S$, где $S$ --- определяет множество всех доступных состояний.

Каждый ход приводит к изменениям некоторой окружающей среды (адаптивное проблемное пространство с такими атрибутами, как переменные, граничные значения, правила и допустимые действия). В свою очередь, окружающая среда выполняет оценку $a_i$-го хода учитывая $s_i$-е состояние. Таким образом, находясь в состоянии $s_i$ алгоритм выполняет поиск $a_i$-го хода, согласно некоторой оценке $r_i$ и получает от окружающей среды новую оценку $r_{i + 1}$, переходя в состояние $s_{i + 1}$ (\refimage{td-schema}).

\image{Схематичное представление процесса обучения с подкреплением}{td-schema}{td-schema}

Подробнее с результатами исследования можно ознакомиться в статье \cite{tdl-gammon}.
