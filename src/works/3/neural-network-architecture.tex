% !TEX TS-program = lualatex
В данном подходе конечная цель заключается в оценке позиции на доске на основе состояния игры, что является задачей регрессии. Таким образом, для заданных входных данных модель <<Многослойный перцептрон>> \cite{mlp} является наиболее эффективной, так как она может моделировать сложные нелинейные взаимосвязи между позициями на доске и соответствующими действиями.

Её вывод вычисляется путём прямого распространения активации от входных узлов $\vec{l_1}$ к выходным узлам $\vec{l_k}$, проходя через один или $k - 2$ внутренних узлов $\vec{l_i}$, называемых скрытыми. Каждое из соединений в сети параметризуется весом $w_{ij}$ с вещественным значением. Каждый узел в сети выдает вещественное число, равное взвешенной линейной сумме входных данных, поступающих в него, за которой следует нелинейная сигмоидальная операция сжатия (\ref{sigmoid}), которая отображает общую сумму входных данных в интервал от 0 до 1 (\ref{sum-layer}).

\begin{equation}\label{sigmoid}
    \sigma(x) = \frac{1}{1 + e^{-x}}
\end{equation}

\begin{equation}\label{sum-layer}
    \vec{l_j}= \sigma \left(\sum_i w_{ij} \vec{l_{j-1}} \right)
\end{equation}

\begin{enumerate}
    \item $\vec{l_j}$ --- вектор активаций на $j$-м слое сети, т.е. выходы нейронов этого слоя.
    \item $\vec{l_{j-1}}$ --- вектор активаций на предыдущем $(j-1)$-м слое.
    \item $w_{ij}$ --- вес, который соединяет $i$-й нейрон предыдущего слоя с $j$-м нейроном текущего слоя.
\end{enumerate}
