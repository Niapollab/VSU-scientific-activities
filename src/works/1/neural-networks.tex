% !TEX TS-program = lualatex
Одним из главных преимуществ полных игровых деревьев является возможность создать непобедимый искусственный интеллект. В начале десятилетия было успешно построено полное дерево для игры шашки \cite{checkersolved}.

Основной проблемой для разработки полных деревьев становится их экспоненциальный рост, поскольку каждый ход увеличивает число возможных исходов. В \refdf{gamedefparams} представлены мощности полных деревьев для некоторых популярных игр.

\begin{df}{|C|C|C|C|}{m}{Мощности полных деревьев для некоторых популярных игр}{gamedefparams}\hline
    Название игры & Степень ветвления дерева $b$ & Глубина дерева игры $d$ & Мощность дерева $b^d$ \\ \hline
    Крестики-нолики & $4$ & $9$ & $262144$  \\ \hline
    Шашки & $2.8$ & $70$ & $2 \times 10^{31}$  \\ \hline
    Шахматы & $35$ & $70$ & $1.22 \times 10^{128}$  \\ \hline
    Нарды & $250$ & $55$ & $7.70 \times 10^{131}$ \\ \hline
    Го & $250$ & $150$ & $4.91 \times 10^{359}$ \\ \hline
\end{df}

Это затрудняет полный анализ или представление всего дерева, особенно в сложных играх с большим количеством возможных ходов и исходов. Одним из возможных решений данной проблемы является аппроксимацию частей дерева, чтобы сделать вычисления выполнимыми. Однако это может привести к неоптимальным стратегиям или упущению важных игровых состояний.

Для решения этой проблемы могут быть применены алгоритмы основанные на нейронных сетях. Нейронная сеть состоит из слоев, узлы которых похожи на связи нейронов в головном мозге. Каждый узел обрабатывает информацию и передает ее на следующий уровень. Сеть обучается, регулируя связи (называемые весами) между узлами на основе полученных данных, таким образом, сеть не обрабатывает всевозможные варианты, а лишь запоминает взаимосвязь между положением фигур в пространстве и необходимым решением.

Нейронные сети принято называть моделями, так как они могут различаться по своему строению. Однако в общем виде, архитектуру любой нейронной сети можно представить следующим образом: на вход нейронной сети подается некоторый набор признаков $F = \{x_1, x_2, ..., x_n\}$, где $n$ -- число входных признаков или размер текущего слоя. Признаком может являться некоторое число или другой набор признаков, что позволяет делать входные данные многомерными. Входной слой передает данные $F$ первому скрытому слою, если в архитектуре есть скрытые слои. Нейрон скрытого слоя связан с некоторым количеством нейронов предыдущего слоя. Связи могут быть представлены в виде неориентированного графа и заданы, как $W_i = \{w_1, w_2, ..., w_k\}$, где $W_i$ -- связи, входящие в $i$-ый нейрон, а $k$ -- число связей. Значение на $W_i$ нейроне вычисляется, как сумма произведений $x_i$ на $w_k$ с последующим применением функции активации, нормализующей итоговое значение на нейроне текущего слоя. На каждом из скрытых слоев может быть применена своя функция активации. В конечном счете, значения с последнего скрытого слоя попадают на выходной слой, работающий аналогичным образом. Значения, полученные на выходном слое или выходной вектор, является ответом нейронной сети и может быть интерпретирован в зависимости от задачи.
